---
title: "18S_commands_2023&2024"
author: "Gemma Clucas"
date: "2025-08-29"
output: github_document
---

```{r setup, include=FALSE}
options(scipen=999)
knitr::opts_chunk$set(echo = TRUE, digits = 1)
knitr::opts_chunk$set(save_output = FALSE) # prevent outputs being over-written on knitting
library(tidyverse)
library(knitr)
library(qiime2R)

```

## 1. Import the data

Data is spread across plate 75, 76, 99, 100, 101, and 102. Plate 76 and 102 I combined into one plate for PCR and sequencing, as they were both partial extraction plates.

For some reason, there were hidden copies of all files in the folders for plate 100 and 101, which I had to get rid of (viewed them with `ls -a` and delete with `rm .*`) before I could import into qiime.

There were also five LESP samples from Mat Rock on plate 76, so I moved them out to their own folder

```
cd /Users/gc547/Dropbox/GitHub_copied/Fecal_metabarcoding/Middleton-Island_2023-2024_KD/18S
conda activate qiime2-amplicon-2024.10 

for K in 75 76-102 99 100 101; do
qiime tools import\
  --type 'SampleData[PairedEndSequencesWithQuality]'\
  --input-path /Volumes/Data_SS1/18S/Plate$K/reads/ \
  --input-format CasavaOneEightSingleLanePerSampleDirFmt\
  --output-path demux_Plate$K.qza
done

for K in 75 76-102 99 100 101; do
  qiime demux summarize \
    --i-data demux_Plate$K.qza \
    --o-visualization demux_Plate$K.qzv
done
``` 

## 2. Trim primers using cutadapt

The 18S sequences are:

F primer: GGTCTGTGATGCCCTTAGATG (21 bp)   
R primer: GGTGTGTACAAAGGGCAGGG (20 bp)


### Trim 3’ ends first
At the 3’ end of the read, the primer will have been read through after reading the 18S region. I need to be looking for the reverse complement of the reverse primer in read 1 (—p-adapter-f) and the reverse complement of the forward primer in R2 (—p-adapter-r).

F primer reverse complement: CATCTAAGGGCATCACAGACC   
R primer reverse complement: CCCTGCCCTTTGTACACACC
```
for K in 75 76-102 99 100 101; do
  qiime cutadapt trim-paired \
    --i-demultiplexed-sequences demux_Plate$K.qza \
    --p-adapter-f CCCTGCCCTTTGTACACACC \
    --p-adapter-r CATCTAAGGGCATCACAGACC \
    --o-trimmed-sequences trimd_Plate$K.qza \
    --verbose > cutadapt_out_Plate$K.txt
done
```

To see how much passed the filters:
```
for K in 75 76-102 99 100 101; do
  grep "Total written (filtered):" cutadapt_out_Plate$K.txt 
done
```
This is very consistent with 74 - 77% passing the filters, which is typical for this marker.

### Trim 5’ ends of reads
All R1 should begin with the forward primer: GGTCTGTGATGCCCTTAGATG (21 bases). All R2 should begin with the reverse primer: GGTGTGTACAAAGGGCAGGG (20 bases).

Trim these with the following commands:
```
for K in 75 76-102 99 100 101; do
  qiime cutadapt trim-paired \
    --i-demultiplexed-sequences trimd_Plate$K.qza \
    --p-front-f GGTCTGTGATGCCCTTAGATG \
    --p-front-r GGTGTGTACAAAGGGCAGGG \
    --o-trimmed-sequences trimd2_Plate$K.qza \
    --verbose > cutadapt_out2_Plate$K.txt
done
```
To see how much passed the filters:
```
for K in 75 76-102 99 100 101; do
  grep "Total written (filtered):" cutadapt_out2_Plate$K.txt 
done
```
89% passes here, also normal.

## 3. Denoise with Dada2

```
for K in 75 76-102 99 100 101; do
  qiime dada2 denoise-paired \
    --i-demultiplexed-seqs trimd2_Plate$K.qza \
    --p-trunc-len-f 150 \
    --p-trunc-len-r 150 \
    --p-trim-left-f 0 \
    --p-trim-left-r 0 \
    --p-min-overlap 50 \
    --p-n-threads 8 \
    --o-representative-sequences rep-seqs_Plate$K \
    --o-table table_Plate$K \
    --o-denoising-stats denoise_Plate$K
done
```

Create visualizations for the denoising stats.
```
for K in 75 76-102 99 100 101; do  
  qiime metadata tabulate\
    --m-input-file denoise_Plate$K.qza\
    --o-visualization denoise_Plate$K.qzv
done
```

## 4. Merge across plates

```
qiime feature-table merge \
  --i-tables table_Plate75.qza \
  --i-tables table_Plate76-102.qza \
  --i-tables table_Plate99.qza \
  --i-tables table_Plate100.qza \
  --i-tables table_Plate101.qza \
  --p-overlap-method sum \
  --o-merged-table merged-table.qza

qiime feature-table summarize \
    --i-table merged-table.qza \
    --m-sample-metadata-file metadata.txt \
    --o-visualization merged-table
    
qiime feature-table merge-seqs \
  --i-data rep-seqs_Plate75.qza \
  --i-data rep-seqs_Plate76-102.qza \
  --i-data rep-seqs_Plate99.qza \
  --i-data rep-seqs_Plate100.qza \
  --i-data rep-seqs_Plate101.qza \
  --o-merged-data merged_rep-seqs.qza

qiime feature-table tabulate-seqs \
  --i-data merged_rep-seqs.qza \
  --o-visualization merged_rep-seqs.qzv
```


## 5. Assign taxonomy using Naive Bayes classifier

I am going to use the same classifier that I trained for Will's puffin samples. I just copied it from the storm petrel folder into here. Notes on how I trained it are in the repo for his analysis.

I copied the metadata file over from the MiFish folder and changed underscores to hyphens.

```
qiime feature-classifier classify-sklearn \
  --i-classifier classifier.qza \
  --i-reads merged_rep-seqs.qza \
  --o-classification sklearn_taxonomy.qza
  
qiime taxa barplot\
   --i-table merged-table.qza \
   --i-taxonomy sklearn_taxonomy.qza \
   --m-metadata-file metadata.txt \
   --o-visualization barplot_before_filtering.qzv
   
   
```
The blanks seems to mostly have fungal DNA in them, so that we can easily filter out. Lots of fish DNA in the samples.

## 6. Filter out non-prey sequences

```
qiime taxa filter-table \
  --i-table merged-table.qza \
  --i-taxonomy sklearn_taxonomy.qza \
  --p-include Metazoa \
  --o-filtered-table merged-table_onlymetazoa.qza
  
qiime taxa barplot\
      --i-table merged-table_onlymetazoa.qza\
      --i-taxonomy sklearn_taxonomy.qza\
      --m-metadata-file metadata.txt\
      --o-visualization barplot_sklearn-taxa_onlymetazoa

```

Need to filter for just prey next with Katelyn. I downloaded the level 6 version for her to work on. This is what we decided to keep:

```
qiime taxa filter-table \
  --i-table merged-table_onlymetazoa.qza \
  --i-taxonomy sklearn_taxonomy.qza \
  --p-include Teleostei,Batoidea,Scyphozoa,Semaeostomeae,Tentaculata,Hydroidolina,Phyllodocida,Calanoida,Teuthida,Eumalacostraca,Pedunculata \
  --o-filtered-table merged-table_onlyprey.qza
  
qiime taxa barplot\
      --i-table merged-table_onlyprey.qza \
      --i-taxonomy sklearn_taxonomy.qza\
      --m-metadata-file metadata.txt\
      --o-visualization barplot_onlyprey 
```

## 7. Read into R to calculate depth of samples and blanks

### Read in feature table, taxonomy, and metadata

Make sure that file paths do not overwrite the MiFish ones.
```{r}
# Read in the QIIME 2 artifacts and metadata
# Replace file paths with your actual file paths
feature_table <- read_qza("18S/merged-table_onlyprey.qza")
taxonomy_data <- read_qza("18S/sklearn_taxonomy.qza")
metadata <- read_q2metadata("18S/metadata.txt")

# Convert feature table to data frame
feature_table_df <- as.data.frame(feature_table$data) %>%
  rownames_to_column("FeatureID")

# Clean up taxonomy data
taxonomy_clean <- taxonomy_data$data %>%
  parse_taxonomy() %>%  # This splits the taxonomy string into columns
  rownames_to_column("FeatureID")

# Reshape feature table to long format
feature_long <- feature_table_df %>%
  gather(key = "SampleID", value = "Abundance", -FeatureID)

# Merge all data together
complete_data <- feature_long %>%
  left_join(taxonomy_clean, by = "FeatureID") %>%
  left_join(metadata, by = "SampleID")

```

### Calculate read depth of samples vs blanks


```{r}
# Calculate average read depths by Type and Plate
read_depth_comparison <- complete_data %>%
  group_by(SampleID, Type, Plate) %>%
  summarise(TotalReads = sum(Abundance)) %>%
  group_by(Type, Plate) %>%
  summarise(
    MeanReads = round(mean(TotalReads), 2),
    MedianReads = round(median(TotalReads), 2),
    SDReads = round(sd(TotalReads), 2),
    n = n()
  )

# Create empty list to store results for each plate
plate_results <- list()

# Process each plate separately
for(current_plate in unique(complete_data$Plate)) {
  # Get all expected types from metadata for this plate
  expected_types <- metadata %>%
    filter(Plate == current_plate) %>%
    pull(Type) %>%
    unique()
  
  # Get actual total reads for blanks and mock (this only sums real data)
  ext_blank_total_reads <- complete_data %>%
    filter(Plate == current_plate, Type == "EXTBLANK") %>%
    group_by(SampleID) %>%
    summarise(TotalReads = sum(Abundance)) %>%
    pull(TotalReads) %>%
    sum()
    
  fld_blank_total_reads <- complete_data %>%
    filter(Plate == current_plate, Type == "FLDBLANK") %>%
    group_by(SampleID) %>%
    summarise(TotalReads = sum(Abundance)) %>%
    pull(TotalReads) %>%
    sum()
    
  pcr_blank_total_reads <- complete_data %>%
    filter(Plate == current_plate, Type == "PCRBLANK") %>%
    group_by(SampleID) %>%
    summarise(TotalReads = sum(Abundance)) %>%
    pull(TotalReads) %>%
    sum()
    
  # Get true numbers from metadata
  true_ext_blank_number <- metadata %>% 
    filter(Plate == current_plate, Type == "EXTBLANK") %>% 
    nrow()
    
  true_fld_blank_number <- metadata %>% 
    filter(Plate == current_plate, Type == "FLDBLANK") %>% 
    nrow()
    
  true_pcr_blank_number <- metadata %>% 
    filter(Plate == current_plate, Type == "PCRBLANK") %>% 
    nrow()
  
  # Filter data for current plate
  plate_data <- read_depth_comparison %>% filter(Plate == current_plate)
  
  # Calculate adjusted averages using true totals and true numbers
  adjusted_ext_blank_avg <- ext_blank_total_reads / true_ext_blank_number
  adjusted_fld_blank_avg <- fld_blank_total_reads / true_fld_blank_number
  adjusted_pcr_blank_avg <- pcr_blank_total_reads / true_pcr_blank_number
  sample_avg <- plate_data$MeanReads[plate_data$Type == "SAMPLE"]
  
  # Create base comparison dataframe with all expected types
  adjusted_comparison <- data.frame(
    Type = expected_types,
    Plate = current_plate,
    MeanReads = 0,
    MedianReads = 0,
    SDReads = 0,
    n = 0,
    PercentOfSample = 0
  )
  
  # Update with actual data where available
  for(type in unique(plate_data$Type)) {
    idx <- adjusted_comparison$Type == type
    if(any(idx)) {
      adjusted_comparison[idx, "MeanReads"] <- plate_data$MeanReads[plate_data$Type == type]
      adjusted_comparison[idx, "MedianReads"] <- plate_data$MedianReads[plate_data$Type == type]
      adjusted_comparison[idx, "SDReads"] <- plate_data$SDReads[plate_data$Type == type]
      adjusted_comparison[idx, "n"] <- plate_data$n[plate_data$Type == type]
    }
  }
  
  # Update blank rows with adjusted means and true n
  if("EXTBLANK" %in% expected_types) {
    adjusted_comparison$MeanReads[adjusted_comparison$Type == "EXTBLANK"] <- round(adjusted_ext_blank_avg, 2)
    adjusted_comparison$n[adjusted_comparison$Type == "EXTBLANK"] <- true_ext_blank_number
  }
  if("FLDBLANK" %in% expected_types) {
    adjusted_comparison$MeanReads[adjusted_comparison$Type == "FLDBLANK"] <- round(adjusted_fld_blank_avg, 2)
    adjusted_comparison$n[adjusted_comparison$Type == "FLDBLANK"] <- true_fld_blank_number
  }
  if("PCRBLANK" %in% expected_types) {
    adjusted_comparison$MeanReads[adjusted_comparison$Type == "PCRBLANK"] <- round(adjusted_pcr_blank_avg, 2)
    adjusted_comparison$n[adjusted_comparison$Type == "PCRBLANK"] <- true_pcr_blank_number
  }
  
  # Calculate percentages for all types
  adjusted_comparison$PercentOfSample <- round((adjusted_comparison$MeanReads / sample_avg) * 100, 2)
  adjusted_comparison$PercentOfSample[adjusted_comparison$Type == "SAMPLE"] <- 100
  
  # Store results for this plate
  plate_results[[as.character(current_plate)]] <- adjusted_comparison
}


# Calculate combined statistics across all plates
all_plates_summary <- complete_data %>%
  group_by(SampleID, Type) %>%
  summarise(TotalReads = sum(Abundance)) %>%
  group_by(Type) %>%
  summarise(
    MeanReads = round(mean(TotalReads), 2),
    MedianReads = round(median(TotalReads), 2),
    SDReads = round(sd(TotalReads), 2),
    n = n()
  )

# Get true numbers from metadata across all plates
true_ext_blank_number <- metadata %>% 
  filter(Type == "EXTBLANK") %>% 
  nrow()
  
true_fld_blank_number <- metadata %>% 
  filter(Type == "FLDBLANK") %>% 
  nrow()
  
true_pcr_blank_number <- metadata %>% 
  filter(Type == "PCRBLANK") %>% 
  nrow()

# Calculate total reads for each type across all plates
ext_blank_total_reads <- complete_data %>%
  filter(Type == "EXTBLANK") %>%
  group_by(SampleID) %>%
  summarise(TotalReads = sum(Abundance)) %>%
  pull(TotalReads) %>%
  sum()
  
fld_blank_total_reads <- complete_data %>%
  filter(Type == "FLDBLANK") %>%
  group_by(SampleID) %>%
  summarise(TotalReads = sum(Abundance)) %>%
  pull(TotalReads) %>%
  sum()
  
pcr_blank_total_reads <- complete_data %>%
  filter(Type == "PCRBLANK") %>%
  group_by(SampleID) %>%
  summarise(TotalReads = sum(Abundance)) %>%
  pull(TotalReads) %>%
  sum()

# Calculate adjusted averages
adjusted_ext_blank_avg <- ext_blank_total_reads / true_ext_blank_number
adjusted_fld_blank_avg <- fld_blank_total_reads / true_fld_blank_number
adjusted_pcr_blank_avg <- pcr_blank_total_reads / true_pcr_blank_number
sample_avg <- all_plates_summary$MeanReads[all_plates_summary$Type == "SAMPLE"]

# Create base comparison dataframe with all types
all_plates_comparison <- data.frame(
  Type = unique(metadata$Type),
  MeanReads = 0,
  MedianReads = 0,
  SDReads = 0,
  n = 0,
  PercentOfSample = 0
)

# Update with actual data where available
for(type in unique(all_plates_summary$Type)) {
  idx <- all_plates_comparison$Type == type
  if(any(idx)) {
    all_plates_comparison[idx, "MeanReads"] <- all_plates_summary$MeanReads[all_plates_summary$Type == type]
    all_plates_comparison[idx, "MedianReads"] <- all_plates_summary$MedianReads[all_plates_summary$Type == type]
    all_plates_comparison[idx, "SDReads"] <- all_plates_summary$SDReads[all_plates_summary$Type == type]
    all_plates_comparison[idx, "n"] <- all_plates_summary$n[all_plates_summary$Type == type]
  }
}

# Update blank rows with adjusted means and true n
all_plates_comparison$MeanReads[all_plates_comparison$Type == "EXTBLANK"] <- round(adjusted_ext_blank_avg, 2)
all_plates_comparison$n[all_plates_comparison$Type == "EXTBLANK"] <- true_ext_blank_number

all_plates_comparison$MeanReads[all_plates_comparison$Type == "FLDBLANK"] <- round(adjusted_fld_blank_avg, 2)
all_plates_comparison$n[all_plates_comparison$Type == "FLDBLANK"] <- true_fld_blank_number

all_plates_comparison$MeanReads[all_plates_comparison$Type == "PCRBLANK"] <- round(adjusted_pcr_blank_avg, 2)
all_plates_comparison$n[all_plates_comparison$Type == "PCRBLANK"] <- true_pcr_blank_number

# Calculate percentages for all types
all_plates_comparison$PercentOfSample <- round((all_plates_comparison$MeanReads / sample_avg) * 100, 2)
all_plates_comparison$PercentOfSample[all_plates_comparison$Type == "SAMPLE"] <- 100

# Display plate-specific results first
for(plate in names(plate_results)) {
  cat(sprintf("\n### Read Depth Summary - Plate %s\n", plate))
  print(knitr::kable(plate_results[[plate]], 
                     caption = sprintf("Summary of read depths by sample type - Plate %s", plate),
                     col.names = c("Type", "Plate", "Mean Reads", "Median Reads", "SD Reads", "n", "% of Sample Reads"),
                     align = c('l', 'l', 'r', 'r', 'r', 'r', 'r')))
  cat("\n")
}

# Display combined results
cat("\n### Read Depth Summary - All Plates Combined\n")
print(knitr::kable(all_plates_comparison,
                   caption = "Summary of read depths by sample type - All Plates Combined",
                   col.names = c("Type", "Mean Reads", "Median Reads", "SD Reads", "n", "% of Sample Reads"),
                   align = c('l', 'r', 'r', 'r', 'r', 'r')))


# Save all results if requested
if(knitr::opts_chunk$get("save_output")) {
  for(plate in names(plate_results)) {
    write.csv(plate_results[[plate]],
              sprintf("18S/adjusted_read_depth_comparison_plate_%s.csv", plate),
              row.names = FALSE)
  }
  write.csv(all_plates_comparison,
            "18S/adjusted_read_depth_comparison_all_plates.csv",
            row.names = FALSE)
}
```

Field blanks have a depth of 1.59% compared to samples. Extraction blanks 0.65% and PCR blanks <0.01% - great!

## 8. Alpha rarefaction 
```
qiime taxa collapse \
  --i-table merged-table_onlyprey.qza \
  --i-taxonomy sklearn_taxonomy.qza \
  --p-level 6 \
  --o-collapsed-table merged-table_onlyprey_collapsed.qza

qiime diversity alpha-rarefaction \
  --i-table merged-table_onlyprey_collapsed.qza \
  --m-metadata-file metadata.txt \
  --p-min-depth 100 \
  --p-max-depth 10000 \
  --o-visualization alpha-rarefaction-100-10000


qiime diversity alpha-rarefaction \
  --i-table merged-table_onlyprey_collapsed.qza \
  --m-metadata-file metadata.txt \
  --p-min-depth 50 \
  --p-max-depth 1000 \
  --o-visualization alpha-rarefaction-50-1000
```
Species richness does not change between 50 and 1000 reads. Get rid of samples with fewer than 100 reads just to be on the safe side.


## 9. Final filtering

Drop the mock and blanks.
```
qiime feature-table filter-samples \
  --i-table merged-table_onlyprey.qza \
  --p-min-frequency 100 \
  --m-metadata-file metadata.txt \
  --p-where "Type='SAMPLE'" \
  --o-filtered-table merged_table_onlyprey_minfreq100.qza 
```

### Abundance filtering

This is simplest to do on the collapsed version of the table, so it's making calcs at level 6 and not the species/ASV level.

```
qiime taxa collapse \
  --i-table merged_table_onlyprey_minfreq100.qza \
  --i-taxonomy sklearn_taxonomy.qza \
  --p-level 6 \
  --o-collapsed-table merged_table_onlyprey_minfreq100_collapsed.qza
```


```{r}
library(qiime2R)
library(tidyverse)
library(biomformat)

# Read in the QIIME 2 artifacts
feature_table <- read_qza("18S/merged_table_onlyprey_minfreq100_collapsed.qza")

# Convert feature table to data frame
feature_table_df <- as.data.frame(feature_table$data) %>%
  rownames_to_column("TaxonomyID")

# Convert to long format
feature_long <- feature_table_df %>%
  gather(key = "SampleID", value = "Abundance", -TaxonomyID)

# Apply 1% filter per sample
filtered_features <- feature_long %>%
  group_by(SampleID) %>%
  mutate(
    TotalReads = sum(Abundance),
    RelativeAbundance = Abundance / TotalReads,
    Abundance = if_else(RelativeAbundance < 0.01, 0, Abundance)
  ) %>%
  ungroup() %>%
  # Remove taxa that have zero abundance across all samples
  group_by(TaxonomyID) %>%
  filter(sum(Abundance) > 0) %>%
  ungroup()

# Convert back to wide format
filtered_feature_table <- filtered_features %>%
  select(TaxonomyID, SampleID, Abundance) %>%
  pivot_wider(
    names_from = SampleID,
    values_from = Abundance,
    values_fill = 0
  )

# Create output files for QIIME2
# Create feature table in BIOM format
filtered_feature_matrix <- as.matrix(filtered_feature_table[,-1])
rownames(filtered_feature_matrix) <- filtered_feature_table$TaxonomyID

# Create BIOM object
biom_obj <- make_biom(data = filtered_feature_matrix)

# Write BIOM file
write_biom(biom_obj, "18S/filtered_level6_table.biom")

# Create new taxonomy file where Feature IDs match the collapsed taxonomy strings
new_taxonomy_df <- data.frame(
  'Feature ID' = filtered_feature_table$TaxonomyID,
  'Taxon' = filtered_feature_table$TaxonomyID
)

# Write taxonomy file
write.table(new_taxonomy_df,
            "18S/filtered_level6_taxonomy.tsv",
            sep = "\t",
            quote = FALSE,
            row.names = FALSE)

# Print summary statistics
cat("Original number of taxa:", nrow(feature_table_df), "\n")
cat("Number of taxa after filtering:", nrow(filtered_feature_table), "\n")
cat("Number of taxa removed:", nrow(feature_table_df) - nrow(filtered_feature_table), "\n")

# Calculate and print the number of reads before and after filtering
total_reads_before <- sum(feature_long$Abundance)
total_reads_after <- sum(filtered_features$Abundance)
cat("\nTotal reads before filtering:", total_reads_before, "\n")
cat("Total reads after filtering:", total_reads_after, "\n")
cat("Percentage of reads retained:", round(total_reads_after/total_reads_before * 100, 2), "%\n")
```
```
# Import filtered table back into QIIME2
qiime tools import \
  --input-path filtered_level6_table.biom \
  --type 'FeatureTable[Frequency]' \
  --input-format BIOMV100Format \
  --output-path filtered_level6_table_minabund1.qza

sed -i.bak 's/Feature.ID/Feature ID/g' filtered_level6_taxonomy.tsv

# Import new taxonomy file
qiime tools import \
  --input-path filtered_level6_taxonomy.tsv \
  --type 'FeatureData[Taxonomy]' \
  --input-format TSVTaxonomyFormat \
  --output-path filtered_level6_taxonomy_minabund1.qza

# Make a barplot with the new taxonomy file
qiime taxa barplot \
  --i-table filtered_level6_table_minabund1.qza \
  --i-taxonomy filtered_level6_taxonomy_minabund1.qza \
  --m-metadata-file metadata.txt \
  --o-visualization barplot_level6_minfreq100_minabund1.qzv
```

I think this is done? Just need to download and send back to Katelyn.